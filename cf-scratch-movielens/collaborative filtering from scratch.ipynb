{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c01341af646d3b0ee211791509c9a1fd",
     "grade": false,
     "grade_id": "cell-c221f36c8cb8cc40",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Recommendation systems\n",
    "Welcome to your first homework assignment about recommendation systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "72f19a9d892bcda62e9635861cacb735",
     "grade": false,
     "grade_id": "cell-5ceae71aaff52339",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## The Cold Start Problem \n",
    "\n",
    "The colaborative filtering method discussed in class does not address the problem of new user or new movies. What prediction would you use in these cases:\n",
    "\n",
    "* A new user but a known movie\n",
    "* A new movie and a known user\n",
    "* A new user and new movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c2dc894c710542e44999fba60b401868",
     "grade": true,
     "grade_id": "cell-65c54ba14a58709f",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**A new user but a known movie**:\n",
    "* Option 1: We can predict average rating given to that movie by existing users\n",
    "* Option 2 (better): We can collect information like demographics, declared interest at the time of signup, current location, and data from his initial interaction with the platform (clicks,search history). Based on the information collected, we can match up the new user with existing user profiles. Then we can predict the rating as the average of the ratings given to that movie by the user profiles which are close to the new user.\n",
    "\n",
    "**A new movie but a known user**:\n",
    "For a new movie we can create a movie profile: genre, director, cast, release date, language, length etc. Then for the existing user we can create a similar profile based on the movies that he has rates. For ex: What is the probability that the concerned user likes horror movie or movie by Christopher Nolan. Then we can use the similarity between the movie and user profile to predict the rating. We can also factor in user bias based on his existing rating. This will tell us whether he has a critical rater or liberal rater.\n",
    "\n",
    "**A new movie and a new user**:\n",
    "For the new movie, we can create a movie profile: genre, director, cast, release date, language, length etc.\n",
    "For the new user, we can collect information like demographics, declared interest at the time of signup, current location, and data from his initial interaction with the platform (clicks,search history).\n",
    "Now from the pool of existing users and movies, we can filter out movies that are closer to the profile of new movie and filter out users that are closer to the profile of new user and then we can take the average of ratings given to the filtered movies by the filtered users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5d98647caefbe861f117cdde5d30cc40",
     "grade": false,
     "grade_id": "cell-d43d0152c6b4e82f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Matrix Factorization with bias\n",
    "We want to extend the Matrix Factorization model discussed in class to add a \"bias\" parameter for each user and another \"bias\" parameter for each movie.  For the problem in class we had the parameters matrix $U$ and $V$, we are adding $u^0$ which is a vector of dimension $n_u$ and $v^0$ which is a vector of dimension $n_m$. The equations\n",
    "\n",
    "$$\\hat{y}_{ij} = u_{0i} + v_{0j} + u_i \\cdot v_j  $$ \n",
    " \n",
    "(a) How many weights (parameters) are we fitting for this problem?\n",
    "\n",
    "(b) Write the gradient descent equations for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "582dbd6ac3203c6be51c3b3d89732ff9",
     "grade": true,
     "grade_id": "cell-d553da17ca4564e8",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "(a) Assuming the dimension of U and V are $n_u$ x k and $n_m$ x k, the number of parameters: $$n_u * k + n_m * k + n_u+n_m$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Vectorized version:\n",
    "   $$1.\\: u^0 = u^0 - \\eta * \\nabla E(u^0) \\;where \\; \\nabla E(u^0)=-2*np.sum((Y-UV^T-u^0-v^{0T})*R,axis = 0)/N$$ <br/>\n",
    "   $$2.\\: v^0 = v^0 - \\eta * \\nabla E(v^0) \\;where \\; \\nabla E(v^0)=-2*(np.sum((Y-UV^T-u^0-v^{0T})*R,axis = 1))^T/N$$<br/>\n",
    "   \n",
    "   $$3. \\: U = U - \\eta * \\nabla E(U)\\;where \\; \\nabla E(U)=-2*((Y-UV^T-u^0-v^{0T})*R)V)/N$$<br/>\n",
    "   $$4. \\:V = V - \\eta * \\nabla E(V) \\;where \\; \\nabla E(V)=-2*((Y-UV^T-u^0-v^{0T})*R)^TU)/N$$<br/>\n",
    "   \n",
    "   where $R$ is the binarized version of $Y$\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5d46c5ebd4701c30e558eb55caea82a2",
     "grade": false,
     "grade_id": "cell-a3ecbb6da6a04705",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Collaborative Filtering with Gradient Descent \n",
    "\n",
    "In this part of the assignment you will build a collaborative filtering model to predict netflix ratings.  This assignment will step you through how to do this using stochastic gradient descent. The data for this assignment is ...\n",
    "\n",
    "**Instructions:**\n",
    "- Do not use loops (for/while) in your code, unless the instructions explicitly ask you to do so.\n",
    "- DO NOT change paths (-3 points)\n",
    "- DO NOT submit data to github (-2 points)\n",
    "\n",
    "**You will learn to:**\n",
    "- Build the general architecture of a learning algorithm, including:\n",
    "    - Encoding rating data\n",
    "    - Initializing parameters\n",
    "    - Calculating the cost function\n",
    "    - Calculating gradient\n",
    "    - Using an optimization algorithm (gradient descent) \n",
    "    - Predicting on new data\n",
    "- Putting it all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bcaa736523b6e2ff0267a99e13938158",
     "grade": false,
     "grade_id": "cell-0ea2a22f6bbdabbc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Encoding rating data\n",
    "Here are our very small subset of fake data to get us started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId,movieId,rating\r\n",
      "11,1,4\r\n",
      "11,23,5\r\n",
      "2,23,5\r\n",
      "2,4,3\r\n",
      "31,1,4\r\n",
      "31,23,4\r\n",
      "4,1,5\r\n",
      "4,3,2\r\n",
      "52,1,1\r\n",
      "52,3,4\r\n",
      "61,3,5\r\n",
      "7,23,1\r\n",
      "7,3,3\r\n"
     ]
    }
   ],
   "source": [
    "# The first row says that user 1 reated movie 11 with a score of 4\n",
    "!cat tiny_training2.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "14535f6dc2c9b8a691698d3d28f21b89",
     "grade": false,
     "grade_id": "cell-44b682275c3630cc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# here is a handy function from fast.ai\n",
    "def proc_col(col):\n",
    "    \"\"\"Encodes a pandas column with continous ids. \n",
    "    \"\"\"\n",
    "    uniq = col.unique()\n",
    "    name2idx = {o:i for i,o in enumerate(uniq)}\n",
    "    return name2idx, np.array([name2idx[x] for x in col]), len(uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "04f2fd8d1394e69d038ecc4e1d1df6ac",
     "grade": false,
     "grade_id": "cell-41f615ff687624c5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def encode_data(df):\n",
    "    \"\"\"Encodes rating data with continous user and movie ids using \n",
    "    the helpful fast.ai function from above.\n",
    "    \n",
    "    Arguments:\n",
    "      train_csv: a csv file with columns user_id,movie_id,rating \n",
    "    \n",
    "    Returns:\n",
    "      df: a dataframe with the encode data\n",
    "      num_users\n",
    "      num_movies\n",
    "      \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    _,user_col,num_users = proc_col(df.userId)\n",
    "    _,movie_col,num_movies = proc_col(df.movieId)\n",
    "    df.userId = user_col\n",
    "    df.movieId = movie_col\n",
    "#     raise NotImplementedError()\n",
    "    return df, num_users, num_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d68d9f144f61298588aa5501486d093b",
     "grade": false,
     "grade_id": "cell-20524cf964cd86f3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tiny_training2.csv\")\n",
    "df, num_users, num_movies = encode_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating\n",
       "0        0        0       4\n",
       "1        0        1       5\n",
       "2        1        1       5\n",
       "3        1        2       3\n",
       "4        2        0       4\n",
       "5        2        1       4\n",
       "6        3        0       5\n",
       "7        3        3       2\n",
       "8        4        0       1\n",
       "9        4        3       4\n",
       "10       5        3       5\n",
       "11       6        1       1\n",
       "12       6        3       3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cb4c9b3ca5958683ecdee3371402ee4f",
     "grade": true,
     "grade_id": "cell-9f450c8da332e44a",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(num_users == 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bb477356d1545f228d80f646789249a5",
     "grade": true,
     "grade_id": "cell-e2782b6d1a8b7e78",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(num_movies == 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "509058ab6b95b9e9f9e997fb92bc42ee",
     "grade": true,
     "grade_id": "cell-33d1f1e347947a47",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_equal(df[\"userId\"].values, np.array([0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 6, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fa3e28917ed5d2f1cc3f20d31be5f9e2",
     "grade": true,
     "grade_id": "cell-a17fa0331b6be94d",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b7493f49eec0c1e8e0cb10e3cb3082f0",
     "grade": false,
     "grade_id": "cell-72490bca925d342a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Initializing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "86ad5b49b1e7774aa007d3708b4e20b2",
     "grade": false,
     "grade_id": "cell-86cdf4ce1a4fb8f7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.55790894,  4.69774849,  0.92361109,  1.58739544,  3.00593239],\n",
       "       [ 4.69774849,  7.44656163,  1.18135616,  2.64524868,  4.74559066],\n",
       "       [ 0.92361109,  1.18135616,  0.24548062,  0.34025121,  0.69616965],\n",
       "       [ 1.58739544,  2.64524868,  0.34025121,  1.61561   ,  2.41361975],\n",
       "       [ 3.00593239,  4.74559066,  0.69616965,  2.41361975,  3.82505541],\n",
       "       [ 2.02000808,  3.29656257,  0.43174569,  2.065911  ,  3.07264619],\n",
       "       [ 2.07691001,  3.02887291,  0.53270924,  1.02482544,  1.90251125]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_embedings(n, K):\n",
    "    \"\"\" Create a numpy random matrix of shape n, K\n",
    "    \n",
    "    The random matrix should be initialized with uniform values in (0, 6/K)\n",
    "    Arguments:\n",
    "    \n",
    "    Inputs:\n",
    "    n: number of items/users\n",
    "    K: number of factors in the embeding \n",
    "    \n",
    "    Returns:\n",
    "    emb: numpy array of shape (n, num_factors)\n",
    "    \"\"\"\n",
    "    np.random.seed(3)\n",
    "    emb = 6*np.random.random((n, K)) / K\n",
    "    return emb\n",
    "\n",
    "# here is an example on how the prediction matrix would look like with 7 users and 5 movies\n",
    "np.dot(create_embedings(7,3), create_embedings(5,3).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "77e65bbf9979c9e70ff4f51fd6f205cf",
     "grade": false,
     "grade_id": "cell-beef892ffe04476e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Encoding Y as a sparse matrix\n",
    "This code helps you encode a $Y$ as a sparse matrix from the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ba9e920654a0367a71735df88ee64424",
     "grade": false,
     "grade_id": "cell-147015e836174cf4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "def df2matrix(df, nrows, ncols, column_name=\"rating\"):\n",
    "    \"\"\" Returns a sparse matrix constructed from a dataframe\n",
    "    \n",
    "    This code assumes the df has columns: MovieID,UserID,Rating\n",
    "    \"\"\"\n",
    "    values = df[column_name].values\n",
    "    ind_movie = df['movieId'].values\n",
    "    ind_user = df['userId'].values\n",
    "    return sparse.csc_matrix((values,(ind_user, ind_movie)),shape=(nrows, ncols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5ab1d3d656625a82019fe4f03ba236ca",
     "grade": false,
     "grade_id": "cell-18d0b3280aeb27b0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tiny_training2.csv\")\n",
    "df, num_users, num_movies = encode_data(df)\n",
    "Y = df2matrix(df, num_users, num_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t4\n",
      "  (2, 0)\t4\n",
      "  (3, 0)\t5\n",
      "  (4, 0)\t1\n",
      "  (0, 1)\t5\n",
      "  (1, 1)\t5\n",
      "  (2, 1)\t4\n",
      "  (6, 1)\t1\n",
      "  (1, 2)\t3\n",
      "  (3, 3)\t2\n",
      "  (4, 3)\t4\n",
      "  (5, 3)\t5\n",
      "  (6, 3)\t3\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2a9345f7b923d4b327433ba370b69770",
     "grade": false,
     "grade_id": "cell-c59f98d40119c2b1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def sparse_multiply(df, emb_user, emb_movie):\n",
    "    \"\"\" This function returns U*V^T element wise multi by R as a sparse matrix.\n",
    "    \n",
    "    It avoids creating the dense matrix U*V^T\n",
    "    \"\"\"\n",
    "    df[\"Prediction\"] = np.sum(emb_user[df[\"userId\"].values]*emb_movie[df[\"movieId\"].values], axis=1)\n",
    "    return df2matrix(df, emb_user.shape[0], emb_movie.shape[0], column_name=\"Prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "49c30ebd232f8c363d4551fe16fdb801",
     "grade": false,
     "grade_id": "cell-34b067092cd650f9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Calculating the cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8a8bb24a25d564885c27c26f1663d55f",
     "grade": false,
     "grade_id": "cell-e4b1d37dbcb0c405",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Use vectorized computation for this function. No loops!\n",
    "# Hint: use df2matrix and sparse_multiply\n",
    "def cost(df, emb_user, emb_movie):\n",
    "    \"\"\" Computes mean square error\n",
    "    \n",
    "    First compute prediction. Prediction for user i and movie j is\n",
    "    emb_user[i]*emb_movie[j]\n",
    "    \n",
    "    Arguments:\n",
    "      df: dataframe with all data or a subset of the data\n",
    "      emb_user: embedings for users\n",
    "      emb_movie: embedings for movies\n",
    "      \n",
    "    Returns:\n",
    "      error(float): this is the MSE\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    df[\"Prediction\"] = np.sum(emb_user[df[\"userId\"].values]*emb_movie[df[\"movieId\"].values], axis=1)\n",
    "    error = np.mean(np.square(df.Prediction - df.rating))\n",
    "#     raise NotImplementedError()\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e27109a5852d29a4db2fcd9518f547ee",
     "grade": true,
     "grade_id": "cell-e7b5689049c2f45a",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "emb_user = np.ones((num_users, 3))\n",
    "emb_movie = np.ones((num_movies, 3))\n",
    "error = cost(df, emb_user, emb_movie)\n",
    "assert(np.around(error, decimals=2) == 2.23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d195d7d2bd356f3f7f11cd16bb40acea",
     "grade": false,
     "grade_id": "cell-eecb153a5272d90a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Calculating gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3cb7a507904ee5e83135fb967d762da9",
     "grade": false,
     "grade_id": "cell-745f5e8d9b341426",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def finite_difference(df, emb_user, emb_movie, ind_u=None, ind_m=None, k=None):\n",
    "    \"\"\" Computes finite difference on MSE(U, V).\n",
    "    \n",
    "    This function is used for testing the gradient function. \n",
    "    \"\"\"\n",
    "    e = 0.000000001\n",
    "    c1 = cost(df, emb_user, emb_movie)\n",
    "    K = emb_user.shape[1]\n",
    "    x = np.zeros_like(emb_user)\n",
    "    y = np.zeros_like(emb_movie)\n",
    "    if ind_u is not None:\n",
    "        x[ind_u][k] = e\n",
    "    else:\n",
    "        y[ind_m][k] = e\n",
    "    c2 = cost(df, emb_user + x, emb_movie + y)\n",
    "    return (c2 - c1)/e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ca244b8794ff537cf7b721c8b5e7831d",
     "grade": false,
     "grade_id": "cell-6da7b90b116a6712",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gradient(df, Y, emb_user, emb_movie):\n",
    "    \"\"\" Computes the gradient.\n",
    "    \n",
    "    First compute prediction. Prediction for user i and movie j is\n",
    "    emb_user[i]*emb_movie[j]\n",
    "    \n",
    "    Arguments:\n",
    "      df: dataframe with all data or a subset of the data\n",
    "      Y: sparse representation of df\n",
    "      emb_user: embedings for users\n",
    "      emb_movie: embedings for movies\n",
    "      \n",
    "    Returns:\n",
    "      d_emb_user\n",
    "      d_emb_movie\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    R = Y.sign().todense()\n",
    "    delta = np.multiply(Y.todense(),R) - sparse_multiply(df,emb_user,emb_movie).todense()\n",
    "    d_emb_user = -2*np.dot(delta,emb_movie)/len(Y.data)\n",
    "    d_emb_movie = -2*np.dot(delta.transpose(),emb_user)/len(Y.data)\n",
    "    \n",
    "    return d_emb_user,d_emb_movie\n",
    "#     raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "emb_user = create_embedings(num_users, K)\n",
    "emb_movie = create_embedings(num_movies, K)\n",
    "Y = df2matrix(df, emb_user.shape[0], emb_movie.shape[0])\n",
    "grad_user, grad_movie = gradient(df, Y, emb_user, emb_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f03717bfb40d791bdbae0d4d68975429",
     "grade": true,
     "grade_id": "cell-a58a216f11e292b4",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "user=1\n",
    "approx = np.array([finite_difference(df, emb_user, emb_movie, ind_u=user, k=i) for i in range(K)])\n",
    "assert(np.all(np.abs(grad_user[user] - approx) < 0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4e6877a8f9d3b394fe84b235b1e4b25b",
     "grade": true,
     "grade_id": "cell-4d60664272f913f0",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "movie=1\n",
    "approx = np.array([finite_difference(df, emb_user, emb_movie, ind_m=movie, k=i) for i in range(K)])\n",
    "assert(np.all(np.abs(grad_movie[movie] - approx) < 0.0001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dc8cd2f251b745f930ad1f17ce2ad040",
     "grade": false,
     "grade_id": "cell-75a83a0a289d180c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Using gradient descent with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b7777a7ac0cc550d5d2626e05c036ce3",
     "grade": false,
     "grade_id": "cell-ddc48938c215e395",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# you can use a for loop to iterate through gradient descent\n",
    "def gradient_descent(df, emb_user, emb_movie, iterations=100, learning_rate=0.01, df_val=None):\n",
    "    \"\"\" Computes gradient descent with momentum (0.9) for a number of iterations.\n",
    "    \n",
    "    Prints training cost and validation cost (if df_val is not None) every 50 iterations.\n",
    "    \n",
    "    Returns:\n",
    "    emb_user: the trained user embedding\n",
    "    emb_movie: the trained movie embedding\n",
    "    \"\"\"\n",
    "    Y = df2matrix(df, emb_user.shape[0], emb_movie.shape[0])\n",
    "    # YOUR CODE HERE\n",
    "    grad_u_moment,grad_m_moment = gradient(df,Y,emb_user,emb_movie)\n",
    "    emb_user = np.array(np.subtract(emb_user,learning_rate*grad_u_moment))\n",
    "    emb_movie = np.array(np.subtract(emb_movie,learning_rate*grad_m_moment))\n",
    "\n",
    "    for i in range(iterations-1):\n",
    "        grad_user,grad_movie = gradient(df,Y,emb_user,emb_movie)\n",
    "        grad_u_moment = .9*grad_u_moment+.1*grad_user\n",
    "        grad_m_moment = .9*grad_m_moment + .1*grad_movie\n",
    "        emb_user = np.array(np.subtract(emb_user,learning_rate*grad_u_moment))\n",
    "        emb_movie = np.array(np.subtract(emb_movie,learning_rate*grad_m_moment))\n",
    "        \n",
    "        if df_val is not None and i%50 ==0:\n",
    "            print(\"Training cost:\",cost(df, emb_user, emb_movie))\n",
    "            print(\"Validation cost:\",cost(df_val, emb_user, emb_movie))\n",
    "#     raise NotImplementedError()\n",
    "    return emb_user, emb_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_user = create_embedings(num_users, 3)\n",
    "emb_movie = create_embedings(num_movies, 3)\n",
    "emb_user, emb_movie = gradient_descent(df, emb_user, emb_movie, iterations=200, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "427c2fa6fb1f89a88ae69589e9296744",
     "grade": true,
     "grade_id": "cell-d4f1184eccf7ebe0",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "train_mse = cost(df, emb_user, emb_movie)\n",
    "assert(np.around(train_mse, decimals=2) == 0.53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d63781170ae7aac4f48c6d44afda64e7",
     "grade": false,
     "grade_id": "cell-7b4ece4b4a308a5f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Predicting on new data\n",
    "Now we should write a function that given new data is able to predict ratings. First we write a function that encodes new data. If a new user or item is present that row should be remove. Collaborative Filtering is not good at handling new users or new items. To help with this task, you could write a an auxiliary function similar to `proc_col`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "89b34542423f352f952b8e049875b7ec",
     "grade": false,
     "grade_id": "cell-6535ac40f1132e10",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def encode_new_data(df_val, df_train):\n",
    "    \"\"\" Encodes df_val with the same encoding as df_train.\n",
    "    Returns:\n",
    "    df_val: dataframe with the same encoding as df_train\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    u2idx,_,_ = proc_col(df_train.userId)\n",
    "    m2idx,_,_= proc_col(df_train.movieId)\n",
    "    df_val = df_val.loc[df_val['userId'].isin(u2idx.keys())]\n",
    "    df_val = df_val.loc[df_val['movieId'].isin(m2idx.keys())]\n",
    "    df_val.userId = df_val.userId.apply(lambda x: u2idx[x])\n",
    "    df_val.movieId = df_val.movieId.apply(lambda x: m2idx[x])\n",
    "#     raise NotImplementedError()\n",
    "    return df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.read_csv(\"tiny_training2.csv\")\n",
    "df_v = pd.read_csv(\"tiny_val2.csv\")\n",
    "df_v = encode_new_data(df_v, df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c3738c156a5eea374d2f22cdd05d6090",
     "grade": true,
     "grade_id": "cell-7f72f7f728540e68",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(len(df_v.userId.unique())==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2e35bcd786010b0c84c3ce4218505a33",
     "grade": true,
     "grade_id": "cell-1b3ccc161bd551e7",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(len(df_v) == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8c745aa81080e9eb97ef9f23953fcabf",
     "grade": false,
     "grade_id": "cell-0033372e0e9accd9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Putting it all together\n",
    "For this part you should get data from here\n",
    "`wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20205 19507\n"
     ]
    }
   ],
   "source": [
    "# Don't change this path use a simlink if you have the data somewhere else\n",
    "path = \"ml-latest-small/\"\n",
    "data = pd.read_csv(path + \"ratings.csv\")\n",
    "# sorting by timestamp take as validation data the most recent data doesn't work so let's just take 20%\n",
    "# at random\n",
    "np.random.seed(3)\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train = data[msk].copy()\n",
    "val = data[~msk].copy()\n",
    "df_train, num_users, num_movies = encode_data(train.copy())\n",
    "df_val = encode_new_data(val.copy(), train.copy())\n",
    "print(len(val), len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cost: 12.339832098837672\n",
      "Validation cost: 12.44785275740831\n",
      "Training cost: 9.878326915111817\n",
      "Validation cost: 10.015694669049159\n",
      "Training cost: 7.125120820518513\n",
      "Validation cost: 7.2608494209530665\n",
      "Training cost: 5.167711000844929\n",
      "Validation cost: 5.298338385431961\n",
      "Training cost: 4.041209115702141\n",
      "Validation cost: 4.165483203474745\n",
      "Training cost: 3.3177954868811352\n",
      "Validation cost: 3.430797749047875\n",
      "Training cost: 2.8155930032536434\n",
      "Validation cost: 2.918695474604298\n",
      "Training cost: 2.451351434804249\n",
      "Validation cost: 2.5477432509873417\n",
      "Training cost: 2.1779959134714586\n",
      "Validation cost: 2.2702402399715047\n",
      "Training cost: 1.9669199451659873\n",
      "Validation cost: 2.056784680233289\n",
      "Training cost: 1.7999295462948757\n",
      "Validation cost: 1.8886174999799386\n",
      "Training cost: 1.665034965214191\n",
      "Validation cost: 1.7533785022270296\n",
      "Training cost: 1.5540982598296744\n",
      "Validation cost: 1.642685795669171\n",
      "Training cost: 1.4614491159128065\n",
      "Validation cost: 1.5507049806418736\n",
      "Training cost: 1.383039623475071\n",
      "Validation cost: 1.4732753344058325\n",
      "Training cost: 1.3159140085831869\n",
      "Validation cost: 1.407361980821841\n",
      "Training cost: 1.2578684759300258\n",
      "Validation cost: 1.350704715045327\n",
      "Training cost: 1.207228426792404\n",
      "Validation cost: 1.3015881541318153\n",
      "Training cost: 1.1626995100878128\n",
      "Validation cost: 1.2586881582835718\n",
      "Training cost: 1.1232659585523646\n",
      "Validation cost: 1.220967072232701\n",
      "Training cost: 1.0881197733648835\n",
      "Validation cost: 1.1876007998944016\n",
      "Training cost: 1.0566104237490888\n",
      "Validation cost: 1.1579270370265724\n",
      "Training cost: 1.0282084578243833\n",
      "Validation cost: 1.131407842379225\n",
      "Training cost: 1.002478729854793\n",
      "Validation cost: 1.1076021142103365\n",
      "Training cost: 0.979060399032398\n",
      "Validation cost: 1.0861450373160788\n",
      "Training cost: 0.9576517801268475\n",
      "Validation cost: 1.0667325213007781\n",
      "Training cost: 0.9379987268472932\n",
      "Validation cost: 1.0491092706446266\n",
      "Training cost: 0.9198856255101207\n",
      "Validation cost: 1.033059536314949\n",
      "Training cost: 0.9031283434312947\n",
      "Validation cost: 1.018399873640692\n",
      "Training cost: 0.8875686590539008\n",
      "Validation cost: 1.004973419204563\n",
      "Training cost: 0.8730698278399827\n",
      "Validation cost: 0.9926453302548714\n",
      "Training cost: 0.8595130276830371\n",
      "Validation cost: 0.9812991224884867\n",
      "Training cost: 0.846794491868626\n",
      "Validation cost: 0.9708337082306193\n",
      "Training cost: 0.8348231842316145\n",
      "Validation cost: 0.9611609850863452\n",
      "Training cost: 0.8235189053480856\n",
      "Validation cost: 0.9522038604452084\n",
      "Training cost: 0.8128107439147623\n",
      "Validation cost: 0.9438946234466986\n",
      "Training cost: 0.8026358063602262\n",
      "Validation cost: 0.9361735956885142\n",
      "Training cost: 0.7929381719218995\n",
      "Validation cost: 0.9289880068515788\n",
      "Training cost: 0.7836680311344653\n",
      "Validation cost: 0.9222910527829183\n",
      "Training cost: 0.7747809737959722\n",
      "Validation cost: 0.9160411023220613\n"
     ]
    }
   ],
   "source": [
    "K = 50\n",
    "emb_user = create_embedings(num_users, K)\n",
    "emb_movie = create_embedings(num_movies, K)\n",
    "emb_user, emb_movie = gradient_descent(df_train, emb_user, emb_movie, iterations=2000, learning_rate=1, df_val=df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7665730026459809 0.9104271876851561\n"
     ]
    }
   ],
   "source": [
    "train_mse = cost(df_train, emb_user, emb_movie)\n",
    "val_mse = cost(df_val, emb_user, emb_movie)\n",
    "print(train_mse, val_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "845e5d41e78690e233bb41dfe7c53105",
     "grade": true,
     "grade_id": "cell-edcc7b88956c5e27",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "train_mse = cost(df_train, emb_user, emb_movie)\n",
    "assert(np.around(train_mse, decimals=2) == 0.77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7f4179758fcd26e4e4580b67e2c385cb",
     "grade": true,
     "grade_id": "cell-3638271e7060b741",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "val_mse = cost(df_val, emb_user, emb_movie)\n",
    "assert(np.around(val_mse, decimals=2) == 0.91)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4ef823e96553d40dffd6c71f577df918",
     "grade": false,
     "grade_id": "cell-f4939e57a6b94545",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#  Advanced Recommendation (Optional)\n",
    "Use Regression / Random forest to add other features to your recommendation algorithm. Here are the steps:\n",
    "\n",
    "* Here are potential features: \n",
    "    * user embeding, movie embeding (from the hw)\n",
    "    * movie genres\n",
    "    * daypart features\n",
    "    \n",
    "Other extentions: add regularization to gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bias(n):\n",
    "    \"\"\" Create a numpy random matrix of shape n, 1\n",
    "    \n",
    "    The random matrix should be initialized with zeroes\n",
    "    Arguments:\n",
    "    \n",
    "    Inputs:\n",
    "    n: number of items/users \n",
    "    \n",
    "    Returns:\n",
    "    emb: numpy array of shape (n, 1)\n",
    "    \"\"\"\n",
    "    bias = np.zeros((n,1))\n",
    "    return bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_regularized(df, emb_user, emb_movie,bias_user,bias_movie,lambd):\n",
    "    \"\"\" Computes mean square error\n",
    "    \n",
    "    First compute prediction. Prediction for user i and movie j is\n",
    "    emb_user[i]*emb_movie[j]\n",
    "    \n",
    "    Arguments:\n",
    "      df: dataframe with all data or a subset of the data\n",
    "      emb_user: embedings for users\n",
    "      emb_movie: embedings for movies\n",
    "      \n",
    "    Returns:\n",
    "      error(float): this is the MSE\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    df[\"Prediction\"] = np.squeeze(np.sum(emb_user[df[\"userId\"].values]*emb_movie[df[\"movieId\"].values], axis=1)[:,None]+bias_user[df['userId'].values]+bias_movie[df['movieId'].values])\n",
    "    error = np.mean(np.square(df.Prediction - df.rating))\n",
    "#     raise NotImplementedError()\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_regularized(df, Y, emb_user, emb_movie,bias_user,bias_movie,lambd):\n",
    "    \"\"\" Computes the gradient.\n",
    "    \n",
    "    First compute prediction. Prediction for user i and movie j is\n",
    "    emb_user[i]*emb_movie[j]\n",
    "    \n",
    "    Arguments:\n",
    "      df: dataframe with all data or a subset of the data\n",
    "      Y: sparse representation of df\n",
    "      emb_user: embedings for users\n",
    "      emb_movie: embedings for movies\n",
    "      lambd: regularization parameter\n",
    "      \n",
    "    Returns:\n",
    "      d_emb_user\n",
    "      d_emb_movie\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "#     set_trace()\n",
    "    R = Y.sign().todense()\n",
    "    delta = np.multiply(Y.todense(),R) - sparse_multiply(df,emb_user,emb_movie).todense()-np.multiply(bias_user,R)-np.multiply(bias_movie.T,R)\n",
    "    d_emb_user = -2*np.dot(delta,emb_movie)/len(Y.data) + 2*lambd*emb_user\n",
    "    d_emb_movie = -2*np.dot(delta.transpose(),emb_user)/len(Y.data) +2*lambd*emb_movie\n",
    "    d_bias_user = -2*np.sum(delta,axis=1)/len(Y.data)\n",
    "    d_bias_movie = -2*np.sum(delta,axis=0).T/len(Y.data)\n",
    "    \n",
    "    return d_emb_user,d_emb_movie,d_bias_user,d_bias_movie\n",
    "#     raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use a for loop to iterate through gradient descent\n",
    "def gradient_descent_reg(df, emb_user, emb_movie,bias_user,bias_movie,iterations=100, learning_rate=0.01, df_val=None,lambd=.01):\n",
    "    \"\"\" Computes gradient descent with momentum (0.9) for a number of iterations.\n",
    "    \n",
    "    Prints training cost and validation cost (if df_val is not None) every 50 iterations.\n",
    "    \n",
    "    Returns:\n",
    "    emb_user: the trained user embedding\n",
    "    emb_movie: the trained movie embedding\n",
    "    \"\"\"\n",
    "#     set_trace()\n",
    "    Y = df2matrix(df, emb_user.shape[0], emb_movie.shape[0])\n",
    "    # YOUR CODE HERE\n",
    "    grad_u_moment,grad_m_moment ,grad_ub_moment,grad_mb_moment= gradient_regularized(df,Y,emb_user,emb_movie,bias_user,bias_movie,lambd)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        grad_user,grad_movie,grad_user_bias,grad_movie_bias = gradient_regularized(df,Y,emb_user,emb_movie,bias_user,bias_movie,lambd)\n",
    "        grad_u_moment = .9*grad_u_moment+.1*grad_user\n",
    "        grad_m_moment = .9*grad_m_moment + .1*grad_movie\n",
    "        grad_ub_moment = .9*grad_ub_moment+.1*grad_user_bias\n",
    "        grad_mb_moment = .9*grad_mb_moment + .1*grad_movie_bias        \n",
    "        \n",
    "        emb_user = np.array(np.subtract(emb_user,learning_rate*grad_u_moment))\n",
    "        emb_movie = np.array(np.subtract(emb_movie,learning_rate*grad_m_moment))\n",
    "        bias_user = np.array(np.subtract(bias_user,learning_rate*grad_ub_moment))\n",
    "        bias_movie = np.array(np.subtract(bias_movie,learning_rate*grad_mb_moment))\n",
    "        \n",
    "        if df_val is not None and i%50 ==0:\n",
    "            print(\"Training cost:\",cost_regularized(df, emb_user, emb_movie,bias_user,bias_movie,lambd))\n",
    "            print(\"Validation cost:\",cost_regularized(df_val, emb_user, emb_movie,bias_user,bias_movie,lambd))\n",
    "#     raise NotImplementedError()\n",
    "    return emb_user, emb_movie, bias_user,bias_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20205 19507\n"
     ]
    }
   ],
   "source": [
    "# Don't change this path use a simlink if you have the data somewhere else\n",
    "path = \"ml-latest-small/\"\n",
    "data = pd.read_csv(path + \"ratings.csv\")\n",
    "# sorting by timestamp take as validation data the most recent data doesn't work so let's just take 20%\n",
    "# at random\n",
    "np.random.seed(3)\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train = data[msk].copy()\n",
    "val = data[~msk].copy()\n",
    "df_train, num_users, num_movies = encode_data(train.copy())\n",
    "df_val = encode_new_data(val.copy(), train.copy())\n",
    "print(len(val), len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "671"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8442"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 50\n",
    "emb_user = create_embedings(num_users, K)\n",
    "emb_movie = create_embedings(num_movies, K)\n",
    "bias_user = create_bias((num_users))\n",
    "bias_movie = create_bias((num_movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(671, 50)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8442, 50)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_movie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(671, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_user.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8442, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_movie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df2matrix(df_traxin, emb_user.shape[0], emb_movie.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cost: 12.230724796857148\n",
      "Validation cost: 12.340560392540814\n",
      "Training cost: 6.902039588580828\n",
      "Validation cost: 7.041636459315589\n",
      "Training cost: 4.524842216160127\n",
      "Validation cost: 4.635745256699486\n",
      "Training cost: 3.364780189037686\n",
      "Validation cost: 3.458644312404154\n",
      "Training cost: 2.715302690140108\n",
      "Validation cost: 2.7982122694071387\n",
      "Training cost: 2.312102255737825\n",
      "Validation cost: 2.387494108266488\n",
      "Training cost: 2.0417631370183598\n",
      "Validation cost: 2.1116745803974415\n",
      "Training cost: 1.8490628525866992\n",
      "Validation cost: 1.9147995458781697\n",
      "Training cost: 1.70478093137466\n",
      "Validation cost: 1.767250979614349\n",
      "Training cost: 1.5924258706359546\n",
      "Validation cost: 1.6523037085626466\n",
      "Training cost: 1.5021631241567883\n",
      "Validation cost: 1.559973113477183\n",
      "Training cost: 1.427832741039832\n",
      "Validation cost: 1.4839945590752548\n",
      "Training cost: 1.3654017657158868\n",
      "Validation cost: 1.4202571190085345\n",
      "Training cost: 1.3121229190713581\n",
      "Validation cost: 1.3659527367125712\n",
      "Training cost: 1.2660577594151192\n",
      "Validation cost: 1.3190942228519642\n",
      "Training cost: 1.225795797044042\n",
      "Validation cost: 1.2782313326543442\n",
      "Training cost: 1.19028295116851\n",
      "Validation cost: 1.2422772658995849\n",
      "Training cost: 1.1587131752062383\n",
      "Validation cost: 1.2103989184251607\n",
      "Training cost: 1.1304577925287023\n",
      "Validation cost: 1.1819451857373693\n",
      "Training cost: 1.105018056230114\n",
      "Validation cost: 1.1563987106413396\n",
      "Training cost: 1.0819924383820372\n",
      "Validation cost: 1.1333425153808216\n",
      "Training cost: 1.061053522825034\n",
      "Validation cost: 1.1124363546232134\n",
      "Training cost: 1.04193132248263\n",
      "Validation cost: 1.0933995860627506\n",
      "Training cost: 1.0244009977327566\n",
      "Validation cost: 1.075998518037514\n",
      "Training cost: 1.0082736559422358\n",
      "Validation cost: 1.0600369011581658\n",
      "Training cost: 0.9933893512310847\n",
      "Validation cost: 1.0453486724785048\n",
      "Training cost: 0.9796116838478695\n",
      "Validation cost: 1.031792342883396\n",
      "Training cost: 0.9668235815174143\n",
      "Validation cost: 1.0192466027736535\n",
      "Training cost: 0.9549239670631712\n",
      "Validation cost: 1.0076068442345945\n",
      "Training cost: 0.9438250994494041\n",
      "Validation cost: 0.9967823817016618\n",
      "Training cost: 0.9334504326895536\n",
      "Validation cost: 0.9866942112725341\n",
      "Training cost: 0.9237328773632602\n",
      "Validation cost: 0.9772731898225153\n",
      "Training cost: 0.914613378258934\n",
      "Validation cost: 0.9684585444571069\n",
      "Training cost: 0.9060397424982388\n",
      "Validation cost: 0.9601966441835166\n",
      "Training cost: 0.8979656677876017\n",
      "Validation cost: 0.9524399813984331\n",
      "Training cost: 0.8903499317941151\n",
      "Validation cost: 0.9451463224978871\n",
      "Training cost: 0.8831557121651686\n",
      "Validation cost: 0.938277995733368\n",
      "Training cost: 0.8763500131739912\n",
      "Validation cost: 0.931801291146937\n",
      "Training cost: 0.8699031799209221\n",
      "Validation cost: 0.925685952568386\n",
      "Training cost: 0.8637884848415013\n",
      "Validation cost: 0.9199047456461115\n"
     ]
    }
   ],
   "source": [
    "emb_user, emb_movie, bias_user,bias_movie = gradient_descent_reg(df_train, emb_user, emb_movie,bias_user,bias_movie,iterations=2000,learning_rate=1, df_val=df_val,lambd=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d9bf97cb793157f22b2fd3bdb29eee81",
     "grade": true,
     "grade_id": "cell-0eef10dd6a045d3c",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv('ml-latest-small/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('ml-latest-small/links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_csv('ml-latest-small/tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = [\"Action\",\"Adventure\",\"Animation\",\"Children\",\"Comedy\",\"Crime\",\"Documentary\",\"Drama\",\"Fantasy\",\n",
    " \"Film-Noir\",\"Horror\",\"Musical\",\"Mystery\",\"Romance\",\"Sci-Fi\",\"Thriller\",\"War\",\"Western\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie['genres'] = movie['genres'].str.split('|').apply(lambda x:[1 if i in x else 0 for i in genre]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = movie.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[[\"Action\",\"Adventure\",\"Animation\",\"Children\",\"Comedy\",\"Crime\",\"Documentary\",\"Drama\",\"Fantasy\",\n",
    " \"Film-Noir\",\"Horror\",\"Musical\",\"Mystery\",\"Romance\",\"Sci-Fi\",\"Thriller\",\"War\",\"Western\"]] = pd.DataFrame(movie.genres.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tmp.drop(['genres'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tf = tmp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Release year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tf['release_year'] = movie_tf.title.apply(lambda x: x[-5:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tf = movie_tf.drop(['title'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Number of genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tf['num_genres'] = np.sum(movie_tf.values[:,1:19],axis=1) #adding total number of genres for each movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf = pd.merge(data,movie_tf,how = 'left',on = 'movieId') #joining with ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Year of rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf['rating_year'] = data_tf.timestamp.apply(lambda x:datetime.datetime.fromtimestamp(x).year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf = data_tf.drop(['timestamp'],axis=1) #converting integer to timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf['release_year'] = data_tf.release_year.apply(lambda x: int(x) if x.isdigit() else int(1900)) #extracting year of release: 10 movies don't have year so assigned year as 1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Difference between rating and release year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf['year_diff'] = data_tf['rating_year'] - data_tf['release_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Years elapsed since release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf['years_since_release'] = 2016 - data_tf['release_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Fixing data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf['num_genres'] = data_tf.num_genres.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf[['userId', 'movieId','Action', 'Adventure', 'Animation',\n",
    "       'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "       'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "       'Thriller', 'War', 'Western', 'release_year', 'num_genres',\n",
    "       'rating_year', 'year_diff', 'years_since_release']] = data_tf[['userId', 'movieId','Action', 'Adventure', 'Animation',\n",
    "       'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "       'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "       'Thriller', 'War', 'Western', 'release_year', 'num_genres',\n",
    "       'rating_year', 'year_diff', 'years_since_release']].astype('uint32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Adding decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf['decade'] = data_tf.release_year.apply(lambda x: int(str(x)[2]) if x != 1900 else 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list1 = list(data_tf.movieId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list2 = list(train.movieId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list3 = list(set(movie_list1)-set(movie_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf = data_tf.loc[data_tf['movieId'].isin(movie_list2)] #keeping only those movies for which we have the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "nbgrader": {
     "checksum": "845e5d41e78690e233bb41dfe7c53105",
     "grade": true,
     "grade_id": "cell-edcc7b88956c5e27",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "train_mse = cost(df_train, emb_user, emb_movie)\n",
    "assert(np.around(train_mse, decimals=2) == 0.77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "nbgrader": {
     "checksum": "7f4179758fcd26e4e4580b67e2c385cb",
     "grade": true,
     "grade_id": "cell-3638271e7060b741",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "val_mse = cost(df_val, emb_user, emb_movie)\n",
    "assert(np.around(val_mse, decimals=2) == 0.91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
